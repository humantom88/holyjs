# История одной оптимизации производительности Node.js библиотеки

Андрей Печкуров
github.com/puzpuzpuz

---

Основные темы
- Подход к оптимизации производительности NOde.js
- История нкоторых оптимизаций

Знакомство с подопытным

hazelcast IMDG (In-memory-data-grid)

Hazelcast IMDG NodeJS библиоткеа

- "Умная клиентская библиотека (знает топологию кластера, отправляет heartbeat'ы)
- Общается с нодами кластера по открытому бинарному протоколу

Подход к оптимизации

Метрики
- сетевая клиентская библиотека
- нагрузка
- метрики (операции в секунду - throughput, время выполнения операции - latency)
- вспомогательные метрики: (загрузка процессора, потребление памяти)

Latency удобно исследовать в виде гистограмм

Выбор метрик:
- Оптимизируем throughput
- Желаемые значения (чем больше, тем лучше)

Бенчмарк

```js
const bennchmark = new Benchmark({
    nextOp: () => map.get('foo'),
    totalOpsCount: REQ_COUNT,
    batchSize: BATCH_SIZE
});

await benchmark.run();
```

Сценарий бенчмарка
(фотка)
- приложение-бенчмарк + кластер IMDG (1нода)
- Фиксированные версии linux, node.js, IMDG и т.д
- Операции: Map#get() и Map#set()
- Данные: строки с ASCII символами (3B, 1KB, 100KB)
- Замер: несколько запусков и вычисление среднего результата
- Каждый запуск: 1 млн операций с лимитом 100

Горячий путь для бенчмарка
1. Старт операции (создание Promise)
2. Сериализация сообщения в бинарный формат
3. Отправка в socket.write(...)
4. Чтение фрейма в socket.on(data)
5. Десериализация ответа
6. Вызов resolve() у Promise

Вид эксперимента #1
- Proof of concept (PoC)
- Простейший способ опробовать оптимизацию на кодовой базе
- Все средства хороши, но нужен весь функционал кода на горячем пути

Вид эксперимента #2
- Микробенчмарки позволяют быстро проверить гипотезу и/или обосновать результаты PoC
- ___Предупреждение___: могут показывать температуру в Антарктиде
- Использовался фреймворк Benchmark.js (+ node-microtime)

Инструмент #1
- Стандартный профилировщик Node.js
```
node --prof app.js
```
- Основан на V8 sample-based profiler
- Учитывает JS и C++ код
- Можно получить человекочитаемое представление
```
node --prof-process isolate-0xnnnnnnnnnn-v8.log > processed.txt
```

Инструмент #2
- Визуализация отчета профилировщика в виде flame graph
- Отлично работает для event loop'a Nodejs

инструмент - консольная утилита ***0x***

Инструмент #3
- Профилировищк памяти из Chrome DevTools (Node.js)
- Умеет делать heap snapshot, отслеживать аллокации и не только

История замеров:
- Базовый замер get и set (3B, 1KB, 100KB)
- Профилирование тяжелой set (строим flame graph), смотрим, какая операция вызывается наиболее часто
- Выявили на горячем пути много Buffer#alloc()/#allocUnsafe(). А это дорогая операция
- Выполняем PoC с полумерой (увеличиваем стартовый буфер до 1024 байт)
- Получаем прирост для маленьких объектов
- Гипотеза подтверждена

Берем другую операцию get
- Выполняем профилирование и ищем топы
- Пытаемся оптимизировать топы
- Пишем микробенчмарк
- Видим разницу при чтении строчек с ASCII символами
- идем в нативный код V8
- пробуем оптимизировать